{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing \n",
    "\n",
    "Before choosing the frameworks I wanted to test, I considered following choices:\n",
    "\n",
    "Linguist(Github), Enry, Pygments, Guesslang(Microsoft/VSCode)\n",
    "\n",
    "Linguist is used by Github to detect files in a repository. It's written in Ruby and I discovered that it takes a significant amount of time to load the linguist Gem file (around 2 seconds on a modern Ryzen7 processor with a NVME ssd). It uses a number of different approaches to define a list of candidate languages that it feeds into a Bayes classifier to make a final prediction. Enry is a golang port of Linguist and works virtually the same but it runs faster. Pygments is primarily used as a code higlighter but it has the capability to predict the language of the sourcecode. After trying it out on a small portion of my test data I observed that the prediction was wrong most of the time. That's why I didn't consider it any further. Lastly I tested out Guesslang which is used in VSCode to automaticly predict the language of a files. It uses a neural network to make the prediction and after testing it out I found it very promising.\n",
    "\n",
    "In conclusion I am choosing Enry over Linguist because of its edge in performance and the comparison will be between <b>Enry and Guesslang</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers.guesslang_wrapper import detect_guesslang\n",
    "from wrappers.enry_wrapper import detect_enry\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# load paths to data\n",
    "paths = defaultdict(list)\n",
    "data_path = \"./test_data/\"\n",
    "\n",
    "for dir in os.listdir(data_path):\n",
    "    for file in os.listdir(data_path + dir):\n",
    "        paths[dir].append(data_path + dir + \"/\" + file)\n",
    "\n",
    "ground_truth = []\n",
    "paths_flat = []\n",
    "\n",
    "for k in paths:\n",
    "    for p in paths[k]:\n",
    "        ground_truth.append(k)\n",
    "        paths_flat.append(p)\n",
    "\n",
    "def accuracy(preds, gtruth):\n",
    "    wrongly_classified_idcs = []\n",
    "\n",
    "    for idx, t in enumerate(gtruth):\n",
    "        if t != preds[idx]:\n",
    "            wrongly_classified_idcs.append(idx)\n",
    "\n",
    "    return \"Accuracy: \" + str(1 - len(wrongly_classified_idcs) / len(gtruth)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While comparing the two frameworks we will consider two usecases. In the first usecase we input source files with given file extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enry ran in 2 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.9938938618925831'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predcitions enry\n",
    "preds_enry = [p.decode(\"utf-8\") for p in detect_enry(paths_flat, no_ext=False)]\n",
    "accuracy(preds_enry, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31280/31280 [00:53<00:00, 587.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guesslang ran in 54 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.8032608695652174'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predcitions guesslang\n",
    "preds_guesslang = detect_guesslang(paths_flat)\n",
    "accuracy(preds_guesslang, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Enry has a much higher accuracy. That is due to the fact that it uses a sequence of matching strategies like extracting the file extention from the filename or extracting information from a shebang to narrow down the number of possible mathces before falling back on a the Bayesian clasifier. That greatly increases the acuracy and speed in this particualr usecase. Guesslang uses a neural-network instead, to predict a language amongst 50 possible classes, only using the sourcecode as its input feautures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>!!!!Do a bunch of other comparisons, confusion matrix, randomly select missclassified files and analize!!!!</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second use case, we assume we only have the sourcecode available without the file extension. Since Guesslang doesn't consider any other feautures than the code itself, we only rerun the Enry classifyer, but this time with the <b>no-ext</b> flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enry ran in 235 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.4943734015345268'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_enry_no_ext = [p.decode(\"utf-8\") for p in detect_enry(paths_flat, no_ext=True)]\n",
    "accuracy(preds_enry_no_ext, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the accuracy and especially the execution speed of the Enry classifier suffer considerably, if we dont provide further information in form of a file extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97bf38389241882591bc5b58182212ccb7638d7bba8ff68b6ab5f0fdb9d883f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}